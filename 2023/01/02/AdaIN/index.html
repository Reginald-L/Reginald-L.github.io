<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
<meta name="viewport"
      content="width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">

    <meta name="author" content="Reggie">





<title>AdaIN | Reggie&#39;s blog</title>



    <link rel="icon" href="/favicon.jpg">




    <!-- stylesheets list from _config.yml -->
    
    <link rel="stylesheet" href="/css/style.css">
    



    <!-- scripts list from _config.yml -->
    
    <script src="/js/script.js"></script>
    
    <script src="/js/tocbot.min.js"></script>
    



    
    
        <!-- MathJax配置，可通过单美元符号书写行内公式等 -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    "HTML-CSS": {
        preferredFont: "TeX",
        availableFonts: ["STIX","TeX"],
        linebreaks: { automatic:true },
        EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50)
    },
    tex2jax: {
        inlineMath: [ ["$", "$"], ["\\(","\\)"] ],
        processEscapes: true,
        ignoreClass: "tex2jax_ignore|dno",
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
        equationNumbers: { autoNumber: "AMS" },
        noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } },
        Macros: { href: "{}" }
    },
    messageStyle: "none"
    });
</script>
<!-- 给MathJax元素添加has-jax class -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<!-- 通过连接CDN加载MathJax的js代码 -->
<script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


    


<meta name="generator" content="Hexo 6.2.0"></head>

<body>
    <script>
        // this function is used to check current theme before page loaded.
        (() => {
            const currentTheme = window.localStorage && window.localStorage.getItem('theme') || '';
            const isDark = currentTheme === 'dark';
            const pagebody = document.getElementsByTagName('body')[0]
            if (isDark) {
                pagebody.classList.add('dark-theme');
                // mobile
                document.getElementById("mobile-toggle-theme").innerText = "· Dark"
            } else {
                pagebody.classList.remove('dark-theme');
                // mobile
                document.getElementById("mobile-toggle-theme").innerText = "· Light"
            }
        })();
    </script>

    <div class="wrapper">
        <header>
    <nav class="navbar">
        <div class="container">
            <div class="navbar-header header-logo"><a href="/">Reggie&#39;s Blog</a></div>
            <div class="menu navbar-right">
                
                    <a class="menu-item" href="/archives">Posts</a>
                
                    <a class="menu-item" href="/about">About</a>
                
                <input id="switch_default" type="checkbox" class="switch_default">
                <label for="switch_default" class="toggleBtn"></label>
            </div>
        </div>
    </nav>

    
    <nav class="navbar-mobile" id="nav-mobile">
        <div class="container">
            <div class="navbar-header">
                <div>
                    <a href="/">Reggie&#39;s Blog</a><a id="mobile-toggle-theme">·&nbsp;Light</a>
                </div>
                <div class="menu-toggle" onclick="mobileBtn()">&#9776; Menu</div>
            </div>
            <div class="menu" id="mobile-menu">
                
                    <a class="menu-item" href="/archives">Posts</a>
                
                    <a class="menu-item" href="/about">About</a>
                
            </div>
        </div>
    </nav>

</header>
<script>
    var mobileBtn = function f() {
        var toggleMenu = document.getElementsByClassName("menu-toggle")[0];
        var mobileMenu = document.getElementById("mobile-menu");
        if(toggleMenu.classList.contains("active")){
           toggleMenu.classList.remove("active")
            mobileMenu.classList.remove("active")
        }else{
            toggleMenu.classList.add("active")
            mobileMenu.classList.add("active")
        }
    }
</script>
            <div class="main">
                <div class="container">
    
    
        <div class="post-toc">
    <div class="tocbot-list">
    </div>
    <div class="tocbot-list-menu">
        <a class="tocbot-toc-expand" onclick="expand_toc()">Expand all</a>
        <a onclick="go_top()">Back to top</a>
        <a onclick="go_bottom()">Go to bottom</a>
    </div>
</div>

<script>
    var tocbot_timer;
    var DEPTH_MAX = 6;    // 为 6 时展开所有
    var tocbot_default_config = {
        tocSelector: '.tocbot-list',
        contentSelector: '.post-content',
        headingSelector: 'h1, h2, h3, h4, h5',
        orderedList: false,
        scrollSmooth: true,
        onClick: extend_click,
    };

    function extend_click() {
        clearTimeout(tocbot_timer);
        tocbot_timer = setTimeout(function () {
            tocbot.refresh(obj_merge(tocbot_default_config, { hasInnerContainers: true }));
        }, 420); // 这个值是由 tocbot 源码里定义的 scrollSmoothDuration 得来的
    }

    document.ready(function () {
        tocbot.init(obj_merge(tocbot_default_config, { collapseDepth: 1 }));
    });

    function expandToc() {
        var b = document.querySelector('.tocbot-toc-expand');
        var expanded = b.getAttribute('data-expanded');
        expanded ? b.removeAttribute('data-expanded') : b.setAttribute('data-expanded', true);
        tocbot.refresh(obj_merge(tocbot_default_config, { collapseDepth: expanded ? 1 : DEPTH_MAX }));
        b.innerText = expanded ? 'Expand all' : 'Collapse all';
    }

    function go_top() {
        window.scrollTo(0, 0);
    }

    function go_bottom() {
        window.scrollTo(0, document.body.scrollHeight);
    }

    function obj_merge(target, source) {
        for (var item in source) {
            if (source.hasOwnProperty(item)) {
                target[item] = source[item];
            }
        }
        return target;
    }
</script>
    

    
    <article class="post-wrap">
        <header class="post-header">
            <h1 class="post-title">AdaIN</h1>
            
                <div class="post-meta">
                    
                        Author: <a itemprop="author" rel="author" href="/">Reggie</a>
                    

                    
                        <span class="post-time">
                        Date: <a href="#">January 2, 2023&nbsp;&nbsp;15:35:08</a>
                        </span>
                    
                    
                </div>
            
        </header>

        <div class="post-content">
            <h1 id="AdaIN"><a href="#AdaIN" class="headerlink" title="AdaIN"></a>AdaIN</h1><p>论文标题: Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization</p>
<p>本文注重于使用PyTorch来实现AdaIN算法, 关于该算法的理论详细可以参考原论文和 <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/401977002">知乎1</a> 和 <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/158657861">知乎2</a></p>
<p>标题中包含了三个关键点:</p>
<ol>
<li>Arbitrary style: 任意风格</li>
<li>Real-time: 实时迁移</li>
<li>Adaptive Instance Normalization: 自适应实例标准化. 将内容图像Content Images的主要特征的均值和标准差对齐到风格图像 Style Images的均值和标准差.</li>
</ol>
<p>AdaIN的本质其实就是一种正则化规则, 和 Batch_Normalisation 的本质是一样的.</p>
<h1 id="架构图"><a href="#架构图" class="headerlink" title="架构图"></a>架构图</h1><img src="/2023/01/02/AdaIN/AdaIN%E6%9E%B6%E6%9E%84%E5%9B%BE.png" class="" title="AdaIN架构图">

<h1 id="标准化方法"><a href="#标准化方法" class="headerlink" title="标准化方法"></a>标准化方法</h1><h2 id="Batch-Normalisation-BN"><a href="#Batch-Normalisation-BN" class="headerlink" title="Batch Normalisation(BN)"></a>Batch Normalisation(BN)</h2><p>$$<br>BN(x) &#x3D; \gamma (\frac{x-\mu(x)}{\sigma(x)}) + \beta<br>$$<br>其中<br>$$ \mu_c(x) &#x3D; \frac{1}{NHW}\sum_{n&#x3D;1}^N\sum_{h&#x3D;1}^H\sum_{w&#x3D;1}^W x_{nchw} $$<br>$$ \sigma_c(x) &#x3D; \sqrt{\frac{1}{NHW}\sum_{n&#x3D;1}^N\sum_{h&#x3D;1}^H\sum_{w&#x3D;1}^W (x_{nchm}) - \mu_c(x))^2 + \epsilon} $$</p>
<h2 id="Instance-Normalisation-IN"><a href="#Instance-Normalisation-IN" class="headerlink" title="Instance Normalisation(IN)"></a>Instance Normalisation(IN)</h2><p>$$<br>IN(x) &#x3D; \gamma (\frac{x-\mu(x)}{\sigma(x)}) + \beta<br>$$<br>其中<br>$$ \mu_{nc}(x) &#x3D; \frac{1}{HW}\sum_{h&#x3D;1}^H\sum_{w&#x3D;1}^W x_{nchw} $$<br>$$ \sigma_{nc}(x) &#x3D; \sqrt{\frac{1}{HW}\sum_{h&#x3D;1}^H\sum_{w&#x3D;1}^W (x_{nchm}) - \mu_{nc}(x))^2 + \epsilon} $$</p>
<p>通常情况下 IN的效果优于BN<br>这些算法都需要模型在归一化数据前先去学习 $\gamma$ 和 $\beta$</p>
<h1 id="AdaIN归一化"><a href="#AdaIN归一化" class="headerlink" title="AdaIN归一化"></a>AdaIN归一化</h1><p>$$<br>AdaIN(x,y) &#x3D; \sigma(y)(\frac{x - \mu(x)}{\sigma(x)}) + \mu(y)<br>$$<br>其中<br>$x$ 和 $y$ 分别表示内容图像和风格图像数据, $\mu(y)$ 和 $\sigma(y)$ 分别表示风格图像数据的均值和标准差. 可以看出AdaIN算法的核心就是用风格图像数据来对内容图像进行归一化.</p>
<h1 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h1><p>从架构图中可以看出, 包含了一个Encoder和一个Decoder, 其中Encoder是基于VGG19的, 而Decoder则是和Encoder对称的一个网络架构.</p>
<h2 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h2><ol>
<li>先用Encoder对Content_Images和Style_Images分别提取对应的特征, 两个特征向量都是512维的.</li>
<li>使用AdaIN算法融合两个特征向量, 得到向量 $t$ $$t &#x3D; AdaIN(f(c), f(s))$$</li>
<li>用Decoder对特征 $t$ 进行还原, 解析为一个 [B, C, H, W] 形状的图像.</li>
<li>使用同一个Encoder对还原后的图像和风格图进行特征提取, 计算其损失函数.</li>
</ol>
<h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><p>$$ L &#x3D; L_c + L_s $$</p>
<p>其中</p>
<p>$$ L_c &#x3D; ||f(g(t)) - t||_2 $$</p>
<p>$$ L_{s1} &#x3D; \sum_{i&#x3D;1}^{L}|| \mu(\varphi(g(t))) - \mu(\varphi(s)) ||_2 $$</p>
<p>$$ L_{s2} &#x3D; \sum_{i&#x3D;1}^{L}|| \sigma(\varphi(g(t))) - \sigma(\varphi(s)) ||_2 $$</p>
<p>$$ L_s &#x3D; L_{s1} + L_{s2} $$</p>
<p>其中<br>$L_c$ 和 $L_s$ 其实就是两个个均方误差, </p>
<ul>
<li>$L_c$ 计算生成的图像向量和特征 $t$之间的欧式距离</li>
<li>$ L_s $ 由两部分组成, 分别是风格图像和生成的图像之间的按层损失.</li>
</ul>
<h1 id="代码实现-1"><a href="#代码实现-1" class="headerlink" title="代码实现"></a>代码实现</h1><h2 id="Encoder"><a href="#Encoder" class="headerlink" title="Encoder"></a>Encoder</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"># 定义Encoder</span><br><span class="line"># 加载预训练的vgg19模型</span><br><span class="line">vgg = torchvision.models.vgg19(pretrained=True)</span><br><span class="line"># 提取预训练vgg16的特征层</span><br><span class="line">vgg_features_layers = vgg.features</span><br><span class="line"></span><br><span class="line">class VGG_Encoder(nn.Module):</span><br><span class="line">    &#x27;&#x27;&#x27;</span><br><span class="line">    输入shape: [B, 3, 64, 64]</span><br><span class="line">    输出shape: [B, 512, 4, 4]</span><br><span class="line">    &#x27;&#x27;&#x27;</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super().__init__()</span><br><span class="line">        # 分层, 按输出通道数进行分层, </span><br><span class="line">        # 比如 </span><br><span class="line">        #   3 -&gt; 64 一层; </span><br><span class="line">        #   64 -&gt; 128 二层</span><br><span class="line">        #   128 -&gt; 256 三层</span><br><span class="line">        #   256 -&gt; 512 四层</span><br><span class="line">        self.slice1 = vgg_features_layers[0:2]</span><br><span class="line">        self.slice2 = vgg_features_layers[2:7]</span><br><span class="line">        self.slice3 = vgg_features_layers[7:12]</span><br><span class="line">        self.slice4 = vgg_features_layers[12:21]</span><br><span class="line">        for param in self.parameters():</span><br><span class="line">            param.requires_grad = False</span><br><span class="line"></span><br><span class="line">    def forward(self, input, only_get_last_output=False):</span><br><span class="line">        output1 = self.slice1(input)</span><br><span class="line">        output2 = self.slice2(output1)</span><br><span class="line">        output3 = self.slice3(output2)</span><br><span class="line">        output = self.slice4(output3)</span><br><span class="line">        if only_get_last_output:</span><br><span class="line">            return output</span><br><span class="line">        else:</span><br><span class="line">            return output1, output2, output3, output</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="AdaIN操作"><a href="#AdaIN操作" class="headerlink" title="AdaIN操作"></a>AdaIN操作</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"># 计算均值和标准差</span><br><span class="line">def get_mean_std(features, eps=1e-5):</span><br><span class="line">    &#x27;&#x27;&#x27;</span><br><span class="line">    features.shape ==&gt; [B, C, H, W]</span><br><span class="line">    return: [B, C, 1, 1]</span><br><span class="line"></span><br><span class="line">    步骤:</span><br><span class="line">        1. [B, C, H, W] --&gt; [B, C, H*W] 4维张量转为3维</span><br><span class="line">        2. 计算每个通道的均值和标准差, i.e., 在dim=2上进行均值和标准差计算</span><br><span class="line">    &#x27;&#x27;&#x27;</span><br><span class="line">    # step 1: [B, C, H, W] --&gt; [B, C, H*W]</span><br><span class="line">    batch_size, channels = features.shape[:2]</span><br><span class="line">    features = features.view((batch_size, channels, -1))</span><br><span class="line">    # step 2: 计算均值和标准差</span><br><span class="line">    mean = features.mean(dim=2).view((batch_size, channels, 1, 1))</span><br><span class="line">    std = (features.var(dim=2) + eps).view((batch_size, channels, 1, 1))</span><br><span class="line">    return mean, std</span><br><span class="line"># AdaIN操作</span><br><span class="line">def adaIN(content_features, style_features):</span><br><span class="line">    &#x27;&#x27;&#x27;</span><br><span class="line">    content_features 和 style_features是由content_image 和 style_image经过VGG_encoder后提取到的特征向量</span><br><span class="line">    两个特征向量具有一样的形状 (B, 512, H, W)</span><br><span class="line">    &#x27;&#x27;&#x27;</span><br><span class="line">    # step 1: 计算content_features和style_features的均值和标准差</span><br><span class="line">    content_mean, content_std = get_mean_std(content_features)</span><br><span class="line">    style_mean, style_std = get_mean_std(style_features)</span><br><span class="line">    # step 2: style_std * ((x-mean) / std) + style_mean</span><br><span class="line">    adaIN_features = style_std * ((content_features - content_mean) / content_std) + style_mean</span><br><span class="line">    return adaIN_features</span><br></pre></td></tr></table></figure>
<h2 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">class Decoder(nn.Module):</span><br><span class="line">    &#x27;&#x27;&#x27;</span><br><span class="line">    输入shape: [B, 512, 4, 4]</span><br><span class="line">    输出shape: [B, 3, 64, 64]</span><br><span class="line">    &#x27;&#x27;&#x27;</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super().__init__()</span><br><span class="line">        def conv_relu_block(in_channels, out_channels, k=3, padding=1, last_block=False):</span><br><span class="line">            if last_block:</span><br><span class="line">                return nn.Sequential(</span><br><span class="line">                    nn.ReflectionPad2d((padding, padding, padding, padding)),</span><br><span class="line">                    nn.Conv2d(in_channels, out_channels, kernel_size=k)</span><br><span class="line">                )</span><br><span class="line">            else: </span><br><span class="line">                return nn.Sequential(</span><br><span class="line">                    nn.ReflectionPad2d((padding, padding, padding, padding)),</span><br><span class="line">                    nn.Conv2d(in_channels, out_channels, kernel_size=k),</span><br><span class="line">                    nn.ReLU(inplace=True)</span><br><span class="line">                )</span><br><span class="line">        self.model = nn.Sequential(</span><br><span class="line">            conv_relu_block(512, 256, k=3, padding=1), </span><br><span class="line">            # 进行上采样</span><br><span class="line">            nn.Upsample(scale_factor=2, mode=&#x27;nearest&#x27;),</span><br><span class="line">            conv_relu_block(256, 256, k=3, padding=1),</span><br><span class="line">            conv_relu_block(256, 256, k=3, padding=1),</span><br><span class="line">            conv_relu_block(256, 256, k=3, padding=1),</span><br><span class="line">            conv_relu_block(256, 128, k=3, padding=1),</span><br><span class="line">            nn.Upsample(scale_factor=2, mode=&#x27;nearest&#x27;),</span><br><span class="line">            conv_relu_block(128, 128, k=3, padding=1),</span><br><span class="line">            conv_relu_block(128, 64, k=3, padding=1),</span><br><span class="line">            nn.Upsample(scale_factor=2, mode=&#x27;nearest&#x27;),</span><br><span class="line">            conv_relu_block(64, 64, k=3, padding=1),</span><br><span class="line">            conv_relu_block(64, 3, k=3, padding=1, last_block=True),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    def forward(self, input):</span><br><span class="line">        output = self.model(input)</span><br><span class="line">        return output</span><br></pre></td></tr></table></figure>
<h2 id="构造AdaIN模型"><a href="#构造AdaIN模型" class="headerlink" title="构造AdaIN模型"></a>构造AdaIN模型</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">def init_weight(m):</span><br><span class="line">    classname = m.__class__.__name__</span><br><span class="line">    if classname.find(&quot;Conv&quot;) != -1:</span><br><span class="line">        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)</span><br><span class="line"></span><br><span class="line">class AdaIN_Net(nn.Module):</span><br><span class="line">    def __init__(self):</span><br><span class="line">        super().__init__()</span><br><span class="line">        self.encoder = VGG_Encoder()</span><br><span class="line">        self.decoder = Decoder().apply(init_weight)</span><br><span class="line"></span><br><span class="line">    @staticmethod</span><br><span class="line">    def get_loss_lc(gen_img_features, t):</span><br><span class="line">        &#x27;&#x27;&#x27;</span><br><span class="line">        计算content_image的损失函数, 生成图像和特征t之间的欧式距离</span><br><span class="line">        gen_img_features: 生成的图像通过Encoder后得到的特征向量</span><br><span class="line">        &#x27;&#x27;&#x27;</span><br><span class="line">        return F.mse_loss(gen_img_features, t)</span><br><span class="line"></span><br><span class="line">    @staticmethod</span><br><span class="line">    def get_loss_ls(style_img_features, gen_img_features):</span><br><span class="line">        ls = 0.0</span><br><span class="line">        for i, (style, gen) in enumerate(zip(style_img_features, gen_img_features)):</span><br><span class="line">            # 计算均值和标准差</span><br><span class="line">            style_mean, style_std = get_mean_std(style)</span><br><span class="line">            gen_mean, gen_std = get_mean_std(gen)</span><br><span class="line">            # 计算LS, 两部分组成</span><br><span class="line">            ls += F.mse_loss(style_mean, gen_mean) + F.mse_loss(style_std, gen_std)</span><br><span class="line">        return ls</span><br><span class="line"></span><br><span class="line">    def forward(self, content_images, style_images, lamda=10):</span><br><span class="line">        content_features = self.encoder(content_images, only_get_last_output=True) # 用于合成特征t</span><br><span class="line">        layered_style_features = self.encoder(style_images) # 用于计算LS</span><br><span class="line">        style_features = layered_style_features[-1] # 用于合成特征t</span><br><span class="line">        # 计算AdaIN特征</span><br><span class="line">        t = adaIN(content_features, style_features)</span><br><span class="line">        # 将 特征 t 通过Decoder</span><br><span class="line">        generated_imgs = self.decoder(t)</span><br><span class="line">        # 将合成的图像通过encoder获得其特征, 需要进行分层</span><br><span class="line">        layered_gen_img_features = self.encoder(generated_imgs) # 这个特征用于计算LS</span><br><span class="line">        gen_img_features = layered_gen_img_features[-1] # 这个特征用于计算LC</span><br><span class="line">        # 计算loss</span><br><span class="line">        lc_loss = self.get_loss_lc(gen_img_features, t)</span><br><span class="line">        ls_loss = self.get_loss_ls(layered_style_features, layered_gen_img_features)</span><br><span class="line">        loss = lc_loss + lamda * ls_loss</span><br><span class="line">        return generated_imgs, loss</span><br></pre></td></tr></table></figure>
<h2 id="优化器"><a href="#优化器" class="headerlink" title="优化器"></a>优化器</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 优化器</span><br><span class="line">optimiser = torch.optim.Adam(model.decoder.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))</span><br></pre></td></tr></table></figure>
<h2 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"># 训练</span><br><span class="line">for epoch in range(opt.epochs):</span><br><span class="line">    for i, (content_imgs, style_imgs) in tqdm(enumerate(zip(content_loader, style_loader))):</span><br><span class="line">        # adjust_learning_rate(optimiser, iteration_count=i)</span><br><span class="line">        # 移动到GPU</span><br><span class="line">        content_imgs = content_imgs.cuda() if cuda else content_imgs</span><br><span class="line">        style_imgs = style_imgs.cuda() if cuda else style_imgs</span><br><span class="line">        # 计算loss</span><br><span class="line">        optimiser.zero_grad()</span><br><span class="line">        generated_imgs, loss = model(content_imgs, style_imgs)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimiser.step()</span><br><span class="line">    print(f&#x27;[epoch: &#123;epoch+1&#125; / &#123;opt.epochs&#125; loss: &#123;float(loss):.6f&#125;]&#x27;)</span><br><span class="line">    # 保存模型</span><br><span class="line">    torch.save(model.state_dict(), f&#x27;&#123;opt.saved_model&#125;/&#123;epoch&#125;_epoch.pth&#x27;)</span><br><span class="line">    # 保存图像</span><br><span class="line">    fp = os.path.join(opt.save_path, &#x27;%s.png&#x27;%(str(epoch + 1)))</span><br><span class="line">    imgs = torch.cat([content_imgs, style_imgs, generated_imgs], dim=3)</span><br><span class="line">    nrow = content_imgs.shape[0]</span><br><span class="line">    save_image(imgs.data, fp=fp, nrow=nrow, normalize=True)</span><br></pre></td></tr></table></figure>

<h1 id="结果展示"><a href="#结果展示" class="headerlink" title="结果展示"></a>结果展示</h1><p>模型还在训练中, 放一个训练了2个epoch的结果.</p>
<img src="/2023/01/02/AdaIN/%E7%BB%93%E6%9E%9C1.png" class="" title="结果展示2个epochs">

<h1 id="完整代码链接"><a href="#完整代码链接" class="headerlink" title="完整代码链接"></a>完整代码链接</h1><p><a target="_blank" rel="noopener" href="https://github.com/Reginald-L/AdaIN">https://github.com/Reginald-L/AdaIN</a></p>
<h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><ul>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/401977002">图片风格迁移算法 AdaIN</a></li>
<li><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/158657861">AdaIN 笔记</a></li>
</ul>

        </div>

        
            <section class="post-copyright">
                
                    <p class="copyright-item">
                        <span>Author:</span>
                        <span>Reggie</span>
                    </p>
                
                
                    <p class="copyright-item">
                        <span>Permalink:</span>
                        <span><a href="https://reginald-l.github.io/2023/01/02/AdaIN/">https://reginald-l.github.io/2023/01/02/AdaIN/</a></span>
                    </p>
                
                
                    <p class="copyright-item">
                        <span>License:</span>
                        <span>Copyright (c) 2022 <a target="_blank" rel="noopener" href="http://creativecommons.org/licenses/by-nc/4.0/">CC-BY-NC-4.0</a> LICENSE</span>
                    </p>
                
                
                     <p class="copyright-item">
                         <span>Slogan:</span>
                         <span><strong>I am a slow walker, but I never walk backwards!!!</strong></span>
                     </p>
                

            </section>
        
        <section class="post-tags">
            <div>
                <span>Tag(s):</span>
                <span class="tag">
                    
                    
                        <a href="/tags/AdaIN/"># AdaIN</a>
                    
                        <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"># 深度学习</a>
                    
                        <a href="/tags/%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90/"># 图像生成</a>
                    
                        <a href="/tags/%E5%9B%BE%E5%83%8F%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB/"># 图像风格迁移</a>
                    
                        
                </span>
            </div>
            <div>
                <a href="javascript:window.history.back();">back</a>
                <span>· </span>
                <a href="/">home</a>
            </div>
        </section>
        <section class="post-nav">
            
                <a class="prev" rel="prev" href="/2023/01/07/sklearn/">机器学习-sklearn</a>
            
            
            <a class="next" rel="next" href="/2022/12/28/CDCGAN/">CDCGAN</a>
            
        </section>


    </article>
</div>

            </div>
            <footer id="footer" class="footer">
    <div class="copyright">
        <span> Copyright © Reggie | 2022 </span>
    </div>
</footer>

    </div>
</body>

</html>