<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
<meta name="viewport"
      content="width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">

    <meta name="author" content="Reggie">





<title>Logistic_Regression | Reggie&#39;s blog</title>



    <link rel="icon" href="/favicon.jpg">




    <!-- stylesheets list from _config.yml -->
    
    <link rel="stylesheet" href="/css/style.css">
    



    <!-- scripts list from _config.yml -->
    
    <script src="/js/script.js"></script>
    
    <script src="/js/tocbot.min.js"></script>
    



    
    
        <!-- MathJax配置，可通过单美元符号书写行内公式等 -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    "HTML-CSS": {
        preferredFont: "TeX",
        availableFonts: ["STIX","TeX"],
        linebreaks: { automatic:true },
        EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50)
    },
    tex2jax: {
        inlineMath: [ ["$", "$"], ["\\(","\\)"] ],
        processEscapes: true,
        ignoreClass: "tex2jax_ignore|dno",
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
        equationNumbers: { autoNumber: "AMS" },
        noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } },
        Macros: { href: "{}" }
    },
    messageStyle: "none"
    });
</script>
<!-- 给MathJax元素添加has-jax class -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<!-- 通过连接CDN加载MathJax的js代码 -->
<script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


    


<meta name="generator" content="Hexo 6.2.0"></head>

<body>
    <script>
        // this function is used to check current theme before page loaded.
        (() => {
            const currentTheme = window.localStorage && window.localStorage.getItem('theme') || '';
            const isDark = currentTheme === 'dark';
            const pagebody = document.getElementsByTagName('body')[0]
            if (isDark) {
                pagebody.classList.add('dark-theme');
                // mobile
                document.getElementById("mobile-toggle-theme").innerText = "· Dark"
            } else {
                pagebody.classList.remove('dark-theme');
                // mobile
                document.getElementById("mobile-toggle-theme").innerText = "· Light"
            }
        })();
    </script>

    <div class="wrapper">
        <header>
    <nav class="navbar">
        <div class="container">
            <div class="navbar-header header-logo"><a href="/">Reggie&#39;s Blog</a></div>
            <div class="menu navbar-right">
                
                    <a class="menu-item" href="/archives">Posts</a>
                
                    <a class="menu-item" href="/about">About</a>
                
                <input id="switch_default" type="checkbox" class="switch_default">
                <label for="switch_default" class="toggleBtn"></label>
            </div>
        </div>
    </nav>

    
    <nav class="navbar-mobile" id="nav-mobile">
        <div class="container">
            <div class="navbar-header">
                <div>
                    <a href="/">Reggie&#39;s Blog</a><a id="mobile-toggle-theme">·&nbsp;Light</a>
                </div>
                <div class="menu-toggle" onclick="mobileBtn()">&#9776; Menu</div>
            </div>
            <div class="menu" id="mobile-menu">
                
                    <a class="menu-item" href="/archives">Posts</a>
                
                    <a class="menu-item" href="/about">About</a>
                
            </div>
        </div>
    </nav>

</header>
<script>
    var mobileBtn = function f() {
        var toggleMenu = document.getElementsByClassName("menu-toggle")[0];
        var mobileMenu = document.getElementById("mobile-menu");
        if(toggleMenu.classList.contains("active")){
           toggleMenu.classList.remove("active")
            mobileMenu.classList.remove("active")
        }else{
            toggleMenu.classList.add("active")
            mobileMenu.classList.add("active")
        }
    }
</script>
            <div class="main">
                <div class="container">
    
    
        <div class="post-toc">
    <div class="tocbot-list">
    </div>
    <div class="tocbot-list-menu">
        <a class="tocbot-toc-expand" onclick="expand_toc()">Expand all</a>
        <a onclick="go_top()">Back to top</a>
        <a onclick="go_bottom()">Go to bottom</a>
    </div>
</div>

<script>
    var tocbot_timer;
    var DEPTH_MAX = 6;    // 为 6 时展开所有
    var tocbot_default_config = {
        tocSelector: '.tocbot-list',
        contentSelector: '.post-content',
        headingSelector: 'h1, h2, h3, h4, h5',
        orderedList: false,
        scrollSmooth: true,
        onClick: extend_click,
    };

    function extend_click() {
        clearTimeout(tocbot_timer);
        tocbot_timer = setTimeout(function () {
            tocbot.refresh(obj_merge(tocbot_default_config, { hasInnerContainers: true }));
        }, 420); // 这个值是由 tocbot 源码里定义的 scrollSmoothDuration 得来的
    }

    document.ready(function () {
        tocbot.init(obj_merge(tocbot_default_config, { collapseDepth: 1 }));
    });

    function expandToc() {
        var b = document.querySelector('.tocbot-toc-expand');
        var expanded = b.getAttribute('data-expanded');
        expanded ? b.removeAttribute('data-expanded') : b.setAttribute('data-expanded', true);
        tocbot.refresh(obj_merge(tocbot_default_config, { collapseDepth: expanded ? 1 : DEPTH_MAX }));
        b.innerText = expanded ? 'Expand all' : 'Collapse all';
    }

    function go_top() {
        window.scrollTo(0, 0);
    }

    function go_bottom() {
        window.scrollTo(0, document.body.scrollHeight);
    }

    function obj_merge(target, source) {
        for (var item in source) {
            if (source.hasOwnProperty(item)) {
                target[item] = source[item];
            }
        }
        return target;
    }
</script>
    

    
    <article class="post-wrap">
        <header class="post-header">
            <h1 class="post-title">Logistic_Regression</h1>
            
                <div class="post-meta">
                    
                        Author: <a itemprop="author" rel="author" href="/">Reggie</a>
                    

                    
                        <span class="post-time">
                        Date: <a href="#">November 7, 2022&nbsp;&nbsp;16:29:45</a>
                        </span>
                    
                    
                </div>
            
        </header>

        <div class="post-content">
            <p>不借助深度学习框架来实现简单的逻辑回归模型来识别猫咪.</p>
<h1 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h1><p>Logistic Regression 用于二分类算法(binary classification)</p>
<p>Logistic Regression可以表示为:<br>$$<br>\hat{y} &#x3D; \sigma(W^T x + b)<br>$$</p>
<p>Loss function:<br>$$<br>L(\hat{y}, y) &#x3D; -(ylog\hat{y} + (1-y)log(1-\hat{y}))<br>$$</p>
<p>Cost function:<br>$$<br>J(w, b) &#x3D; \frac{1}{m} \sum_{i&#x3D;1}^m L(\hat{y}, y) &#x3D; -\frac{1}{m} \sum_{i&#x3D;1}^m [y^{(i)}log\hat{y}^{(i)} + (1 - y^{(i)})log(1 - \hat{y}^{(i)})]<br>$$</p>
<h1 id="猫咪识别"><a href="#猫咪识别" class="headerlink" title="猫咪识别"></a>猫咪识别</h1><p>构建一个逻辑回归模型, 并用它识别猫咪图像.</p>
<h2 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h2><p>使用了两个数据集:</p>
<ul>
<li><p>数据集使用网上关于吴恩达老师逻辑回归的数据集: train_catvnoncat.h5 &amp; test_catvnoncat.h5</p>
<ul>
<li>1 – 表示猫咪 </li>
<li>0 – 表示非猫咪<br>训练样例: <center>
<img style="border-radius: 0.3125em;" 
src="dataset1-examples.png">
<br>
<div style="color:orange; display: inline-block; color: black; padding: 2px; font-size:20px;">数据集1 - 训练样例</div>
</center>
测试样例:
<center>
<img style="border-radius: 0.3125em;" 
src="examples.png">
<br>
<div style="color:orange; display: inline-block; color: black; padding: 2px; font-size:20px;">数据集1 - 测试样例</div>
</center></li>
</ul>
</li>
<li><p>第二个数据集是从Kaggle中下载: <a target="_blank" rel="noopener" href="https://www.kaggle.com/c/dogs-vs-cats/data">https://www.kaggle.com/c/dogs-vs-cats/data</a><br>数据样例:</p>
<ul>
<li>1 – 表示狗 </li>
<li>0 – 表示猫<center>
<img style="border-radius: 0.3125em;" 
src="dataset2-examples.png">
<br>
<div style="color:orange; display: inline-block; color: black; padding: 2px; font-size:20px;">数据集2 - 样例</div>
</center></li>
</ul>
</li>
</ul>
<h2 id="导包"><a href="#导包" class="headerlink" title="导包"></a>导包</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">import os</span><br><span class="line">import numpy as np</span><br><span class="line">import pandas as pd</span><br><span class="line">import random</span><br><span class="line">from PIL import Image</span><br><span class="line">from matplotlib import pyplot as plt</span><br><span class="line">import h5py # 读取h5数据集</span><br></pre></td></tr></table></figure>

<h2 id="图像显示"><a href="#图像显示" class="headerlink" title="图像显示"></a>图像显示</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">def show_img(img_data_set, labels):</span><br><span class="line">    fig = plt.figure(figsize=(15, 8), dpi=80)</span><br><span class="line"></span><br><span class="line">    for i in range(6):</span><br><span class="line">        fig.add_subplot(2, 3, i+1)</span><br><span class="line">        plt.tight_layout()</span><br><span class="line">        plt.imshow(img_data_set[i])</span><br><span class="line">        plt.title(&quot;label: &#123;&#125;&quot;.format(labels[i]))</span><br><span class="line"></span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>

<h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><h3 id="处理数据集-1"><a href="#处理数据集-1" class="headerlink" title="处理数据集 1"></a>处理数据集 1</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">def pro_h5_data(data_path, train=True):</span><br><span class="line">    if train:</span><br><span class="line">        h5_raw_data = os.path.join(data_path, &#x27;data/train_catvnoncat.h5&#x27;)</span><br><span class="line">        h5data = h5py.File(h5_raw_data, &#x27;r&#x27;)</span><br><span class="line">        img_data_x_set, img_data_y_set = h5data[&#x27;train_set_x&#x27;], h5data[&#x27;train_set_y&#x27;] # (64, 64, 3)</span><br><span class="line">    else:</span><br><span class="line">        h5_raw_data = os.path.join(data_path, &#x27;data/test_catvnoncat.h5&#x27;)</span><br><span class="line">        h5data = h5py.File(h5_raw_data, &#x27;r&#x27;)</span><br><span class="line">        img_data_x_set, img_data_y_set = h5data[&#x27;test_set_x&#x27;], h5data[&#x27;test_set_y&#x27;] # (64, 64, 3)</span><br><span class="line">    show_img(img_data_set=img_data_x_set[0:6], labels=img_data_y_set[0:6])</span><br><span class="line">    # print(h5data.keys()) # [&#x27;list_classes&#x27;, &#x27;train_set_x&#x27;, &#x27;train_set_y&#x27;]</span><br><span class="line">    # print(h5data[&#x27;list_classes&#x27;][0], h5data[&#x27;list_classes&#x27;][1]) # b&#x27;non-cat&#x27; b&#x27;cat&#x27;</span><br><span class="line">    </span><br><span class="line">    return np.array(img_data_x_set), np.array(img_data_y_set)</span><br></pre></td></tr></table></figure>
<h3 id="处理数据集-2"><a href="#处理数据集-2" class="headerlink" title="处理数据集 2"></a>处理数据集 2</h3><p>对数据集 2 的处理可以方便以后使用框架加载数据集</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"># 清洗数据</span><br><span class="line">def pro_data(data_path, img_size, start=0, end=100):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    处理训练数据</span><br><span class="line">    data_path: 图像文件所在路径</span><br><span class="line">    0 - 猫</span><br><span class="line">    1 - 狗</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    img_names = os.listdir(data_path)[start:end] # 得到所有的图像名. e.g., cat.0.jpg</span><br><span class="line">    img_data_x_set = []</span><br><span class="line">    img_data_y_set = []</span><br><span class="line">    for item in img_names:</span><br><span class="line">        raw_img = Image.open(os.path.join(data_path, item))</span><br><span class="line">        crop_img = raw_img.resize((img_size, img_size))</span><br><span class="line">        img_data = np.array(crop_img)</span><br><span class="line">        img_data_x_set.append(img_data)</span><br><span class="line">        label = 0 if item.split(r&#x27;.&#x27;)[0] == &#x27;cat&#x27; else 1</span><br><span class="line">        img_data_y_set.append(label)</span><br><span class="line">    return img_data_x_set, img_data_y_set</span><br><span class="line"></span><br><span class="line"># 构造数据集</span><br><span class="line">def build_dataset(path, img_size, train=True):</span><br><span class="line">    &#x27;&#x27;&#x27;</span><br><span class="line">    构造一个数据集, 数据集中的所有数据都被随机打乱, 确保获取数据的随机性</span><br><span class="line">    path: 参数path是数据所在的根目录</span><br><span class="line">    &#x27;&#x27;&#x27;</span><br><span class="line">    if train:</span><br><span class="line">        # 加载猫的数据</span><br><span class="line">        cat_train_data_path = os.path.join(path, &#x27;data/cats_and_dogs/train/cats&#x27;)</span><br><span class="line">        cat_train_x_set, cat_train_y_set = pro_data(cat_train_data_path, img_size=img_size)</span><br><span class="line">        # 加载狗的数据</span><br><span class="line">        dog_train_data_path = os.path.join(path, &#x27;data/cats_and_dogs/train/dogs&#x27;)</span><br><span class="line">        dog_train_x_set, dog_train_y_set = pro_data(dog_train_data_path, img_size=img_size)</span><br><span class="line">    else:</span><br><span class="line">        # 加载猫的数据</span><br><span class="line">        cat_train_data_path = os.path.join(path, &#x27;data/cats_and_dogs/train/cats&#x27;)</span><br><span class="line">        cat_train_x_set, cat_train_y_set = pro_data(cat_train_data_path, img_size=img_size, start=2500, end=2525)</span><br><span class="line">        # 加载狗的数据</span><br><span class="line">        dog_train_data_path = os.path.join(path, &#x27;data/cats_and_dogs/train/dogs&#x27;)</span><br><span class="line">        dog_train_x_set, dog_train_y_set = pro_data(dog_train_data_path, img_size=img_size, start=2500, end=2525)</span><br><span class="line">    # 将两者合并</span><br><span class="line">    train_data_x = cat_train_x_set + dog_train_x_set</span><br><span class="line">    train_data_y = cat_train_y_set + dog_train_y_set</span><br><span class="line">    # 打乱顺序</span><br><span class="line">    train_data = list(zip(train_data_x, train_data_y))</span><br><span class="line">    random.shuffle(train_data)</span><br><span class="line">    train_data_x, train_data_y = zip(*train_data)</span><br><span class="line">    # 随机展示6张</span><br><span class="line">    img_data_set, labels = train_data_x[0:6], train_data_y[0:6]</span><br><span class="line">    show_img(img_data_set, labels)</span><br><span class="line">    return np.array(train_data_x) / 255, np.array(train_data_y)</span><br><span class="line"></span><br><span class="line"># 构造DataLoader</span><br><span class="line">def build_dataloader(X, y, batch_size):</span><br><span class="line">    num_examples = X.shape[0] # 200</span><br><span class="line">    indices = list(range(0, num_examples))</span><br><span class="line">    random.shuffle(indices)</span><br><span class="line">    # print(indices)</span><br><span class="line">    for i in range(0, num_examples, batch_size):</span><br><span class="line">        batch_indices = indices[i : min(i+batch_size, num_examples)]</span><br><span class="line">        # print(type(X[batch_indices]))</span><br><span class="line">        yield X[batch_indices], y[batch_indices]</span><br></pre></td></tr></table></figure>
<h2 id="sigmoid函数"><a href="#sigmoid函数" class="headerlink" title="sigmoid函数"></a>sigmoid函数</h2><p>sigmoid激活函数:<br>$$<br>\sigma(z) &#x3D; \frac{1}{1 + e^{-z}}<br>$$</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">def sigmoid(z):</span><br><span class="line">    return 1 / (1 + np.exp(-z))</span><br></pre></td></tr></table></figure>
<h2 id="L2范数惩罚-防止过拟合"><a href="#L2范数惩罚-防止过拟合" class="headerlink" title="L2范数惩罚 - 防止过拟合"></a>L2范数惩罚 - 防止过拟合</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">def l2_penalty(w):</span><br><span class="line">    return (w**2).sum() / 2</span><br></pre></td></tr></table></figure>
<h2 id="前向传播和反向传播"><a href="#前向传播和反向传播" class="headerlink" title="前向传播和反向传播"></a>前向传播和反向传播</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">def forward(W, b, X, y, lambd):</span><br><span class="line">    &#x27;&#x27;&#x27;</span><br><span class="line">    lambd: 如果使用 L2范数惩罚, 需要使用该参数</span><br><span class="line">    W.shape: (270000, 1)</span><br><span class="line">    X.shape: (6, 270000)</span><br><span class="line">    y.shape: (6, 1)</span><br><span class="line">    &#x27;&#x27;&#x27;</span><br><span class="line">    m = X.shape[0] # m = 6, i.e., m = batch_size</span><br><span class="line">    # print(f&#x27;m = &#123;m&#125;&#x27;)</span><br><span class="line">    Z = np.dot(X, W) + b</span><br><span class="line">    A = sigmoid(Z)</span><br><span class="line">    # cost function</span><br><span class="line">    # 这里 加上 1e-6 是为了防止 log 因为计算值太大而出现溢出的问题</span><br><span class="line">    # cost = (-1/m) * np.sum(y * (np.log(A + 1e-6)) + (1 - y) * (np.log(1 - A  + 1e-6)))  + (lambd / m) * l2_penalty(W)</span><br><span class="line">    cost = (-1/m) * np.sum(y * (np.log(A + 1e-6)) + (1 - y) * (np.log(1 - A  + 1e-6)))</span><br><span class="line">    # 反向传播计算梯度</span><br><span class="line">    # X.T (270000, 6) * (6, 1) = (270000, 1)</span><br><span class="line">    dw = (1 / m) * np.dot(X.T, (A-y))</span><br><span class="line">    db = (1 / m) * np.sum(A - y)</span><br><span class="line">    # print(f&#x27;dw = &#123;dw&#125; \n db = &#123;db&#125;&#x27;)</span><br><span class="line">    grads = &#123;&#x27;dw&#x27;: dw, &#x27;db&#x27;: db&#125;</span><br><span class="line">    return grads, cost</span><br></pre></td></tr></table></figure>
<h2 id="SGD优化算法"><a href="#SGD优化算法" class="headerlink" title="SGD优化算法"></a>SGD优化算法</h2><p>该方法可以使用:</p>
<ul>
<li>SGD</li>
<li>Mini-batch SGD</li>
<li>带有L2范数惩罚的 Mini-batch SGD<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">def optimiser(W, b, X, y, learning_rate):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    Mini-batch SGD</span><br><span class="line">    w -= (learning_rate / |B|) * dw</span><br><span class="line">    b -= (learning_rate / |B|) * db</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    lambd = 3</span><br><span class="line">    B = X.shape[0] # 6</span><br><span class="line">    grads, cost = forward(W, b, X, y, lambd)</span><br><span class="line"></span><br><span class="line">    dw, db = grads[&#x27;dw&#x27;], grads[&#x27;db&#x27;]</span><br><span class="line">    # 带有L2惩罚的SGD</span><br><span class="line">    # W = (1 - (learning_rate * lambd) / B) * W - (learning_rate / B) * dw</span><br><span class="line">    # b = (1 - (learning_rate * lambd) / B) * b - (learning_rate / B) * db</span><br><span class="line">    # Mini-batch SGD</span><br><span class="line">    # W -= (learning_rate / B) * dw</span><br><span class="line">    # b -= (learning_rate / B) * db</span><br><span class="line">    # SGD</span><br><span class="line">    W -= (learning_rate / B) * dw</span><br><span class="line">    b -= (learning_rate / B) * db</span><br><span class="line">    return W, b, cost</span><br></pre></td></tr></table></figure>
<h2 id="初始化参数"><a href="#初始化参数" class="headerlink" title="初始化参数"></a>初始化参数</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">def init_weights(input_dims):</span><br><span class="line">    # W = np.random.normal(loc=0, scale=0.1, size=(input_dims, 1))</span><br><span class="line">    W = np.zeros(shape=(input_dims, 1))</span><br><span class="line">    b = 0</span><br><span class="line">    return W, b</span><br></pre></td></tr></table></figure>
<h2 id="显示Loss变化曲线"><a href="#显示Loss变化曲线" class="headerlink" title="显示Loss变化曲线"></a>显示Loss变化曲线</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">def draw_changes(changes, epochs, title):</span><br><span class="line">    fig = plt.figure(figsize=(15, 8), dpi=80)</span><br><span class="line">    plt.plot(epochs, changes)</span><br><span class="line">    plt.title(title)</span><br><span class="line">    plt.xlabel(&#x27;epochs&#x27;)</span><br><span class="line">    plt.ylabel(&#x27;cost&#x27;)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<h2 id="模型训练"><a href="#模型训练" class="headerlink" title="模型训练"></a>模型训练</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">def trainh5(W, b, num_epochs, learning_rate, X, y):</span><br><span class="line">    print(f&#x27;trainh5_X.shape = &#123;X.shape&#125;&#x27;) # (209, 64, 64, 3)</span><br><span class="line">    print(f&#x27;trainh5_y.shape = &#123;y.shape&#125;&#x27;) # (209,)</span><br><span class="line">    cost_changes = []</span><br><span class="line">    for epoch in range(num_epochs):</span><br><span class="line">        # 构造dataloader</span><br><span class="line">        # X, y = img_data_set, labels</span><br><span class="line">        # 改变数据形状</span><br><span class="line">        X = X.reshape(X.shape[0], -1) # (209, 12288)</span><br><span class="line">        y = y.reshape(-1, 1) # (209, 1)</span><br><span class="line">        # optimiser</span><br><span class="line">        W, b, cost = optimiser(W, b, X, y, learning_rate)</span><br><span class="line">        </span><br><span class="line">        if epoch % 10 == 0:</span><br><span class="line">            print(f&#x27;epoch: &#123;epoch&#125;/&#123;num_epochs&#125; \t loss: &#123;float(cost):.4f&#125;&#x27;)</span><br><span class="line">            cost_changes.append(cost)</span><br><span class="line"></span><br><span class="line">    draw_changes(cost_changes, list(range(0, num_epochs, 10)), &#x27;cost_changes&#x27;)</span><br><span class="line">    return W, b</span><br><span class="line"></span><br><span class="line">def train(W, b, num_epochs, learning_rate, img_data_set, labels):</span><br><span class="line">    cost_changes = []</span><br><span class="line">    for epoch in range(num_epochs):</span><br><span class="line">        # 构造dataloader</span><br><span class="line">        for X, y in build_dataloader(img_data_set, labels, batch_size=128):</span><br><span class="line">            # X, y = img_data_set, labels</span><br><span class="line">            # 改变数据形状</span><br><span class="line">            X = X.reshape(X.shape[0], -1) # (6, 270000) 6是batch_size</span><br><span class="line">            y = y.reshape(-1, 1) # (6, 1)</span><br><span class="line">            # optimiser</span><br><span class="line">            W, b, cost = optimiser(W, b, X, y, learning_rate)</span><br><span class="line">        if epoch % 10 == 0:</span><br><span class="line">            print(f&#x27;epoch: &#123;epoch&#125;/&#123;num_epochs&#125; \t loss: &#123;float(cost):.4f&#125;&#x27;)</span><br><span class="line">            cost_changes.append(cost)</span><br><span class="line"></span><br><span class="line">    draw_changes(cost_changes, list(range(0, num_epochs, 10)), &#x27;cost_changes&#x27;)</span><br><span class="line">    return W, b</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="预测"><a href="#预测" class="headerlink" title="预测"></a>预测</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">def prediction(W, b, train_X, train_y, test_X, test_y):</span><br><span class="line">    # 改变数据形状</span><br><span class="line">    train_X = train_X.reshape(train_X.shape[0], -1) # (6, 270000) 6是batch_size</span><br><span class="line">    train_y = train_y.reshape(-1, 1) # (6, 1)</span><br><span class="line">    A = sigmoid(np.dot(train_X, W) + b)</span><br><span class="line">    for i in range(A.shape[0]):</span><br><span class="line">        A[i][0] = 0 if A[i][0] &lt;= 0.5 else 1</span><br><span class="line"></span><br><span class="line">    print(f&#x27;训练精度: &#123;100 - np.mean(np.abs(A - train_y)) * 100&#125;%&#x27;)</span><br><span class="line"></span><br><span class="line">    test_X = test_X.reshape(test_X.shape[0], -1) # (6, 270000) 6是batch_size</span><br><span class="line">    test_y = test_y.reshape(-1, 1) # (6, 1)</span><br><span class="line">    A = sigmoid(np.dot(test_X, W) + b)</span><br><span class="line">    for i in range(A.shape[0]):</span><br><span class="line">        A[i][0] = 0 if A[i][0] &lt;= 0.5 else 1</span><br><span class="line">    </span><br><span class="line">    print(f&#x27;测试精度: &#123;100 - np.mean(np.abs(A - test_y)) * 100&#125;%&#x27;)</span><br></pre></td></tr></table></figure>

<h2 id="main方法"><a href="#main方法" class="headerlink" title="main方法"></a>main方法</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    root = os.path.abspath(&#x27;.&#x27;)</span><br><span class="line">    # img_size = 300</span><br><span class="line">    # # 构造 train dataset</span><br><span class="line">    # img_data_set, labels = build_dataset(root, img_size=img_size)</span><br><span class="line">    # # 初始化模型参数</span><br><span class="line">    # W, b = init_weights(img_size * img_size * 3)</span><br><span class="line">    # # num_epochs</span><br><span class="line">    # num_epochs = 500</span><br><span class="line">    # # learning_rate</span><br><span class="line">    # learning_rate = 0.0001</span><br><span class="line">    # # train</span><br><span class="line">    # W, b = train(W, b, num_epochs, learning_rate, img_data_set, labels)</span><br><span class="line">    # # 构造 test dataset</span><br><span class="line">    # img_test_data_set, test_labels = build_dataset(root, img_size=img_size, train=False)</span><br><span class="line">    # # prediction</span><br><span class="line">    # prediction(W, b, img_data_set, labels, img_test_data_set, test_labels)</span><br><span class="line"></span><br><span class="line">    X, y = pro_h5_data(root)</span><br><span class="line">    num_epochs = 10000</span><br><span class="line">    learning_rate = 0.000001</span><br><span class="line">    W, b = init_weights(64 * 64 * 3)</span><br><span class="line">    W, b = trainh5(W, b, num_epochs, learning_rate, X, y)</span><br><span class="line">    # 构造测试数据</span><br><span class="line">    test_X, test_y = pro_h5_data(root, train=False)</span><br><span class="line">    prediction(W, b, X, y, test_X, test_y)</span><br></pre></td></tr></table></figure>
<h2 id="结果展示"><a href="#结果展示" class="headerlink" title="结果展示"></a>结果展示</h2><ul>
<li>Loss 变化<center>
  <img style="border-radius: 0.3125em;" 
  src="Loss.png">
  <br>
  <div style="color:orange; display: inline-block; color: black; padding: 2px; font-size:20px;">Loss变化曲线</div>
</center></li>
<li>训练和测试准确率<center>
  <img style="border-radius: 0.3125em;" 
  src="Result.png">
  <br>
  <div style="color:orange; display: inline-block; color: black; padding: 2px; font-size:20px;">准确率</div>
</center></li>
</ul>

        </div>

        
            <section class="post-copyright">
                
                    <p class="copyright-item">
                        <span>Author:</span>
                        <span>Reggie</span>
                    </p>
                
                
                    <p class="copyright-item">
                        <span>Permalink:</span>
                        <span><a href="https://reginald-l.github.io/2022/11/07/Logistic-Regression/">https://reginald-l.github.io/2022/11/07/Logistic-Regression/</a></span>
                    </p>
                
                
                    <p class="copyright-item">
                        <span>License:</span>
                        <span>Copyright (c) 2022 <a target="_blank" rel="noopener" href="http://creativecommons.org/licenses/by-nc/4.0/">CC-BY-NC-4.0</a> LICENSE</span>
                    </p>
                
                
                     <p class="copyright-item">
                         <span>Slogan:</span>
                         <span><strong>I am a slow walker, but I never walk backwards!!!</strong></span>
                     </p>
                

            </section>
        
        <section class="post-tags">
            <div>
                <span>Tag(s):</span>
                <span class="tag">
                    
                    
                        <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"># 深度学习</a>
                    
                        <a href="/tags/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/"># 逻辑回归</a>
                    
                        <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E8%B7%B5/"># 深度学习实践</a>
                    
                        
                </span>
            </div>
            <div>
                <a href="javascript:window.history.back();">back</a>
                <span>· </span>
                <a href="/">home</a>
            </div>
        </section>
        <section class="post-nav">
            
                <a class="prev" rel="prev" href="/2022/11/07/%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0/">激活函数</a>
            
            
            <a class="next" rel="next" href="/2022/10/21/Self-Attention/">Self-Attention</a>
            
        </section>


    </article>
</div>

            </div>
            <footer id="footer" class="footer">
    <div class="copyright">
        <span> Copyright © Reggie | 2022 </span>
    </div>
</footer>

    </div>
</body>

</html>