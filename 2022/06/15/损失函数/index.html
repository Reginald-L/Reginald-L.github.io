<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
<meta name="viewport"
      content="width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">

    <meta name="author" content="Reggie">





<title>损失函数 | Reggie&#39;s blog</title>



    <link rel="icon" href="/favicon.jpg">




    <!-- stylesheets list from _config.yml -->
    
    <link rel="stylesheet" href="/css/style.css">
    



    <!-- scripts list from _config.yml -->
    
    <script src="/js/script.js"></script>
    
    <script src="/js/tocbot.min.js"></script>
    



    
    
        <!-- MathJax配置，可通过单美元符号书写行内公式等 -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    "HTML-CSS": {
        preferredFont: "TeX",
        availableFonts: ["STIX","TeX"],
        linebreaks: { automatic:true },
        EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50)
    },
    tex2jax: {
        inlineMath: [ ["$", "$"], ["\\(","\\)"] ],
        processEscapes: true,
        ignoreClass: "tex2jax_ignore|dno",
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
        equationNumbers: { autoNumber: "AMS" },
        noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } },
        Macros: { href: "{}" }
    },
    messageStyle: "none"
    });
</script>
<!-- 给MathJax元素添加has-jax class -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<!-- 通过连接CDN加载MathJax的js代码 -->
<script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


    


<meta name="generator" content="Hexo 6.2.0"></head>

<body>
    <script>
        // this function is used to check current theme before page loaded.
        (() => {
            const currentTheme = window.localStorage && window.localStorage.getItem('theme') || '';
            const isDark = currentTheme === 'dark';
            const pagebody = document.getElementsByTagName('body')[0]
            if (isDark) {
                pagebody.classList.add('dark-theme');
                // mobile
                document.getElementById("mobile-toggle-theme").innerText = "· Dark"
            } else {
                pagebody.classList.remove('dark-theme');
                // mobile
                document.getElementById("mobile-toggle-theme").innerText = "· Light"
            }
        })();
    </script>

    <div class="wrapper">
        <header>
    <nav class="navbar">
        <div class="container">
            <div class="navbar-header header-logo"><a href="/">Reggie&#39;s Blog</a></div>
            <div class="menu navbar-right">
                
                    <a class="menu-item" href="/archives">Posts</a>
                
                    <a class="menu-item" href="/about">About</a>
                
                <input id="switch_default" type="checkbox" class="switch_default">
                <label for="switch_default" class="toggleBtn"></label>
            </div>
        </div>
    </nav>

    
    <nav class="navbar-mobile" id="nav-mobile">
        <div class="container">
            <div class="navbar-header">
                <div>
                    <a href="/">Reggie&#39;s Blog</a><a id="mobile-toggle-theme">·&nbsp;Light</a>
                </div>
                <div class="menu-toggle" onclick="mobileBtn()">&#9776; Menu</div>
            </div>
            <div class="menu" id="mobile-menu">
                
                    <a class="menu-item" href="/archives">Posts</a>
                
                    <a class="menu-item" href="/about">About</a>
                
            </div>
        </div>
    </nav>

</header>
<script>
    var mobileBtn = function f() {
        var toggleMenu = document.getElementsByClassName("menu-toggle")[0];
        var mobileMenu = document.getElementById("mobile-menu");
        if(toggleMenu.classList.contains("active")){
           toggleMenu.classList.remove("active")
            mobileMenu.classList.remove("active")
        }else{
            toggleMenu.classList.add("active")
            mobileMenu.classList.add("active")
        }
    }
</script>
            <div class="main">
                <div class="container">
    
    
        <div class="post-toc">
    <div class="tocbot-list">
    </div>
    <div class="tocbot-list-menu">
        <a class="tocbot-toc-expand" onclick="expand_toc()">Expand all</a>
        <a onclick="go_top()">Back to top</a>
        <a onclick="go_bottom()">Go to bottom</a>
    </div>
</div>

<script>
    var tocbot_timer;
    var DEPTH_MAX = 6;    // 为 6 时展开所有
    var tocbot_default_config = {
        tocSelector: '.tocbot-list',
        contentSelector: '.post-content',
        headingSelector: 'h1, h2, h3, h4, h5',
        orderedList: false,
        scrollSmooth: true,
        onClick: extend_click,
    };

    function extend_click() {
        clearTimeout(tocbot_timer);
        tocbot_timer = setTimeout(function () {
            tocbot.refresh(obj_merge(tocbot_default_config, { hasInnerContainers: true }));
        }, 420); // 这个值是由 tocbot 源码里定义的 scrollSmoothDuration 得来的
    }

    document.ready(function () {
        tocbot.init(obj_merge(tocbot_default_config, { collapseDepth: 1 }));
    });

    function expandToc() {
        var b = document.querySelector('.tocbot-toc-expand');
        var expanded = b.getAttribute('data-expanded');
        expanded ? b.removeAttribute('data-expanded') : b.setAttribute('data-expanded', true);
        tocbot.refresh(obj_merge(tocbot_default_config, { collapseDepth: expanded ? 1 : DEPTH_MAX }));
        b.innerText = expanded ? 'Expand all' : 'Collapse all';
    }

    function go_top() {
        window.scrollTo(0, 0);
    }

    function go_bottom() {
        window.scrollTo(0, document.body.scrollHeight);
    }

    function obj_merge(target, source) {
        for (var item in source) {
            if (source.hasOwnProperty(item)) {
                target[item] = source[item];
            }
        }
        return target;
    }
</script>
    

    
    <article class="post-wrap">
        <header class="post-header">
            <h1 class="post-title">损失函数</h1>
            
                <div class="post-meta">
                    
                        Author: <a itemprop="author" rel="author" href="/">Reggie</a>
                    

                    
                        <span class="post-time">
                        Date: <a href="#">June 15, 2022&nbsp;&nbsp;9:35:04</a>
                        </span>
                    
                    
                </div>
            
        </header>

        <div class="post-content">
            <h2 id="三个常见的损失函数"><a href="#三个常见的损失函数" class="headerlink" title="三个常见的损失函数"></a>三个常见的损失函数</h2><table>
<thead>
<tr>
<th>损失函数</th>
<th>表达式</th>
</tr>
</thead>
<tbody><tr>
<td>最小二乘法</td>
<td>$\frac{1}{2}(y - \hat y) ^ 2$</td>
</tr>
<tr>
<td>极大似然估计</td>
<td>$-(y\log{\hat y} + (1 - y)\log(1 - \hat{y}) )$</td>
</tr>
<tr>
<td>交叉熵损失</td>
<td>$-(y\log{\hat y} + (1 - y)\log(1 - \hat{y}) )$</td>
</tr>
</tbody></table>
<h2 id="损失函数的引出"><a href="#损失函数的引出" class="headerlink" title="损失函数的引出"></a>损失函数的引出</h2><p>损失函数定量衡量人脑和机器中的两个概率模型. 有一个现实例子可以很好滴拟合损失函数的价值. 在做数学或者其他学科的题目时, 有的时候我们写完一套题后会和答案进行对比, 看看结果相差多少. 这个过程和损失函数的工作原理是基本类似的. 以分类任务为例, 神经网络对提供的数据特征进行学习, 得到一个预测值 $\hat{y}$. 神经网络的训练过程就是通过比较预测值 $\hat y$ 和真实值 $y$ 之间的差异, 不断调整W和b的一个过程. 可以理解为, 损失函数就是告诉机器在学习数据时应该达到一个什么样的目标. 损失函数就是去定量比较预测值和真实值, 这也就解释了为什么在训练过程中我们通常就是对损失函数 $l$ 先求和再计算其梯度, 即 $l.sum().backward()$.</p>
<h2 id="最小二乘法-均方误差"><a href="#最小二乘法-均方误差" class="headerlink" title="最小二乘法 (均方误差)"></a>最小二乘法 (均方误差)</h2><p>最小二乘法是最简单的一个方法. 通俗讲就是直接比较真实值和预测值之间的差距, 比较两个数的大小最常见的就是通过使用绝对值 (L1 Loss), 即 $ | y - \hat y |$. 但是绝对值在零点处不够平滑, 不可导, 这不利于函数收敛和模型的学习. 其优势在于它在0点外的其他地方都有很稳定的梯度, 不容易发生梯度爆炸, 具有很好的鲁棒性. 此外, 它对离散点的包容性很好, 对于离群点不那么敏感, 在一些简单的回归任务中表现的很好. </p>
<img src="/2022/06/15/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/%E7%BB%9D%E5%AF%B9%E5%80%BC.png" class="" title="L1-Loss">

<p>用平方替换绝对值, 就是最小二乘法 (Least square method &#x2F; L2 Loss), 即 $\frac{1}{2}(y - \hat y) ^ 2$. 相比于L1, 最小二乘法在整个定义域上都比较平滑, 全程可导. 而且平方不会影响比较两个数值的大小关系. L2对应的是欧几里得距离(Euclidean distance), 它试图找到一条直线能够使得所有的数据点到直线的欧氏距离最小. 它是机器学习和深度学习中最为常用的一个. 从图可以看出, L2的梯度在每个点都不一样, 离得原点越远其梯度越大, 使用梯度下降法求解的时候梯度很大, 可能导致梯度爆炸. 此外, 它对离群点很敏感, 因为平方的关系, 当误差大于1的时候, 它会把误差放大很多很多.</p>
<img src="/2022/06/15/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/L2.png" class="" title="L2-Loss">

<table>
<thead>
<tr>
<th>method</th>
<th>鲁棒性</th>
<th>离散点</th>
<th>适用场景</th>
<th>收敛速度</th>
</tr>
</thead>
<tbody><tr>
<td>L1</td>
<td>较好</td>
<td>不敏感</td>
<td>简单的回归任务</td>
<td>较慢</td>
</tr>
<tr>
<td>L2</td>
<td>较差</td>
<td>敏感</td>
<td>回归任务</td>
<td>较快</td>
</tr>
</tbody></table>
<h2 id="极大似然估计"><a href="#极大似然估计" class="headerlink" title="极大似然估计"></a>极大似然估计</h2><h3 id="理论"><a href="#理论" class="headerlink" title="理论"></a>理论</h3><p>极大似然估计是根据事实推理可能的概率模型. 先举了例子来解释一下什么是似然. 王木头提供了一个很好理解的一个例子, 即抛硬币. 我们都知道硬币正反面朝上的概率都是50%. 这50%指的是概率. 那么什么是似然呢? 假设我们不知道投硬币的概率, 投了10次硬币, 当硬币落地后正面or反面朝上已经成为一个事实, 有7个正面, 3个反面. 投了10次, 7正3反, 是不是说硬币的概率就一定是正面的概率是0.7, 反面的概率是0.3呢? 虽然这么想很符合我们的直觉, 但这并不是一件板上钉钉的事情. 你可以想一下, 假如说, 我们的硬币是正反概率都是0.5的话, 你抛10次, 难道就真的能保证一定是5次正, 5次反吗? 不一定吧, 出现6正4反, 4正6反也还是挺常见的吧.更甚者, 运气好到极点, 10次全部是正面也是有可能的. 那么, 当我们不知道硬币正反概率的时候, 7正3反, 就一定0.7的概率吗? 也不一定对吧. 完全有可能是, 硬币的概率是0.1正, 0.9反, 但是运气就是很好, 抛出了7正3反的结果. 或者是, 概率本来是0.8正, 0.2反, 但是运气就差那么一点, 抛出了7正3反.  </p>
<table>
<thead>
<tr>
<th></th>
<th>解释</th>
<th>例子</th>
</tr>
</thead>
<tbody><tr>
<td>概率</td>
<td>根据事件所处的环境或者因素来预测事件发生的概率</td>
<td>今天气温是35度, 所以衣服被晾干的概率是90%</td>
</tr>
<tr>
<td>似然</td>
<td>事件已经发生, 根据结果推测事件所处的环境或者因素</td>
<td>衣服被晾干了, 今天气温比较高</td>
</tr>
</tbody></table>
<img src="/2022/06/15/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/%E4%BC%BC%E7%84%B61.png" class="" title="硬币">

<p>总的来说, 在知道既定事实后, 我们虽然没有办法去确定该事实的概率模型, 但是它存在多种有可能的概率模型, 我们可以根据事实去计算每个可能概率模型下的结果, 结果越大越接近真实的概率模型. 投硬币是10次独立事件, 所以 $P(C_1, C_2, ……, C_{10} | \theta) &#x3D; \prod_{i &#x3D; 1}^{10}P(C_i | \theta)$. 至此我们就可以算出来当硬币抛出来正面朝上的概率分别是0.1, 0.7和0.8的时候, 要想得到抛10次硬币7次朝上的概率分布是多少.</p>
<img src="/2022/06/15/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/%E4%BC%BC%E7%84%B6.png" class="" title="硬币">
<p>$0.1^7*0.9^3 &#x3D; 0.0000000729$, $0.7^7*0.3^3 &#x3D; 0.0022235661$, $0.8^7*0.2^3 &#x3D; 0.0016777216$, 这些值被称为似然值. 显然当正面朝上的概率为0.7时似然值最大, 这也为我们直观上感觉应该是0.7和0.3提供了理论依据 (王木头学科学).</p>
<p>总的来说极大似然估计的理论依据就一句话: 事件已经真实发生, 但是我们并不知道它真正的概率模型, 于是存在很多可能的概率模型, 在每一个可能的模型为条件下, 发生这个事件的概率称为似然值. 最大的那个似然值对应的模型就是我们认为和真实概率模型最为接近的.</p>
<h3 id="公式推导"><a href="#公式推导" class="headerlink" title="公式推导"></a>公式推导</h3><p>至此我们已经理解了什么是似然以及极大似然估计的基本原理, 那么极大似然估计损失函数为甚会写成 $-(y\log{\hat y} + (1 - y)\log(1 - \hat{y}) )$ 这样一个样子呢? 下图是对公式的推导过程. </p>
<ul>
<li><p>累乘( $\prod$ ): 理想状态下, 损失函数是符合均值为0, 方差为 $\sigma^2$ 的正态分布的, 且数据集是独立同分布的, 在这个基础上, 联合概率密度等于边缘概率密度的的乘积. 举个赌场的例子来更好滴理解为什么这里是累乘. 比如我们去一个很大的赌场去碰碰运气, 对于我们这样的小白来说, 我们通常是先进去观察别人的胜率怎么样, 然后再决定是玩骰子还是牌九等. 假如我们观察了1000个客户, 在我们评估的时候是把这1000个人同时进行考虑, 然后考虑玩什么比较靠谱. 他们中的每一个人都是我们这个事件的一份子, 这符合概率论中的乘法原理: 完成一件事, 需要分成n个步骤, 每一步都有 $n_i$ 种不同的方案, 则完成这个事件共有N种方法 $N &#x3D; \prod_{i&#x3D;1}^{n} n_i$.</p>
</li>
<li><p>伯努利分布: $ P(x^{(i)}, \theta) &#x3D; \theta^{x^{(i)}} (1-\theta)^{1-x^{(i)}} $</p>
</li>
</ul>
<img src="/2022/06/15/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6%E5%87%BD%E6%95%B0.png" class="" title="极大似然函数">

<h2 id="最小二乘法与极大似然估计的关系"><a href="#最小二乘法与极大似然估计的关系" class="headerlink" title="最小二乘法与极大似然估计的关系"></a>最小二乘法与极大似然估计的关系</h2><p>损失函数在理想状态下是符合均值为0, 方差为 $\sigma^2$ 的正态分布的, 即</p>
<p>$$ f(\epsilon) &#x3D; \frac{1}{\sqrt{2\pi}\sigma} e^{- \frac{(\epsilon-\mu)^2}{2\sigma^2}} $$</p>
<p>线性回归的公式为:</p>
<p>$$ \hat y^{(i)} &#x3D; \theta ^ T x^{(i)} + \epsilon^{(i)} $$</p>
<p>将第二个公式转换为用 $\theta$ 来表示 $ \epsilon $:</p>
<p>$$ \epsilon^{(i)} &#x3D; \hat y^{(i)} - \theta ^ T x^{(i)} $$</p>
<p>将第一个和第三个公式结合可得:</p>
<p>$$ P(\hat y^{(i)} | x^{(i)};\theta) &#x3D; \frac{1}{\sqrt{2\pi}\sigma} exp (-\frac{(\hat y^{(i)} - \theta^T x^{(i)})^2}{2 \sigma^2}) $$</p>
<p>综上似然函数 $ L(\theta) $ 可以表示为:</p>
<p>$$ L(\theta) &#x3D; \prod_{i&#x3D;1}^{m} p(\hat y^{(i)} | x^{(i)};\theta) &#x3D; \prod_{i&#x3D;1}^{m} \frac{1}{\sqrt{2\pi}\sigma} exp (-\frac{(\hat y^{(i)} - \theta^T x^{(i)})^2}{2 \sigma^2}) $$</p>
<p>正如前面提到的, 损失函数的目的是定量衡量真实值和预测值之间的误差. $P(\hat y^{(i)} | x^{(i)};\theta)$ 的意思是 $x^{(i)} 和 \theta$ 的组合值 $ \hat y^{(i)} $ 的概率, 我们的目的是这个概率越大越好, 即预测值等于真实值. 我们的目的就是去寻找什么样的参数 $\theta$ 和我们的数据x组合后正好是真实值. </p>
<p>对数似然: 乘法比较难解, 加法就比较容易多了. log函数里面的乘法转换为加法, 即</p>
<p>$$ \log L(\theta) &#x3D; log \prod_{i&#x3D;1}^{m} \frac{1}{\sqrt{2\pi}\sigma} exp (-\frac{(\hat y^{(i)} - \theta^T x^{(i)})^2}{2 \sigma^2}) $$</p>
<p>转化为加法为:</p>
<p>$$ L(\theta) &#x3D; \sum_{i&#x3D;1}^{m} log \frac{1}{\sqrt{2\pi}\sigma} exp (-\frac{(\hat y^{(i)} - \theta^T x^{(i)})^2}{2 \sigma^2}) $$</p>
<p>在公式 $ \log \frac{1}{\sqrt{2\pi}\sigma} exp (-\frac{(\hat y^{(i)} - \theta^T x^{(i)})^2}{2 \sigma^2})$ 中 $\theta $ 是我们要求解的未知量. 整个式子可以看做是 $\log A B$, 化解得:</p>
<p>$$ m \log \frac{1}{\sqrt{2\pi}\sigma} - \frac{1}{\sigma^2} \cdot \frac{1}{2} \sum_{i&#x3D;1}^m (\hat y^{(i)} - \theta^T x^{(i)})^2 $$</p>
<p>我们的目的是让这个式子越大越好, $m \log \frac{1}{\sqrt{2\pi}\sigma}$ 是一个常数, 且为正数, 后半截也是一个正数, 所以只要后半截越小越好. 再者, $\sigma^2$ 是一个常数, 所以我们的目标可以转换为让下列公式越小越好:</p>
<p>$$ \frac{1}{2} \sum_{i&#x3D;1}^m (\hat y^{(i)} - \theta^T x^{(i)})^2 $$</p>
<p>这不正好是最小二乘法么.</p>
<h2 id="交叉熵损失"><a href="#交叉熵损失" class="headerlink" title="交叉熵损失"></a>交叉熵损失</h2><p>熵(entropy)全名为香农熵, 这个名字来源于信息论之父克劳德 $\cdot$ 香农. 熵在信息论中是用于描述一个系统从不确定到确定状态的难度的一个定量表达. 熵被定义为信息的期望值. 在理解熵之前, 我们先解释一下信息量是什么?</p>
<p>在日常生活中, 有的时候我们在和朋友讨论一些事情的时候会随口说你这个信息量太少了. 在这里我们的意思是你朋友给你的这个消息对你来说你获取的有价值的东西太少了, 通过他的描述, 你依然不知道或者不确定这个事情会如何继续发生下去. 举个例子来解释一下为什么信息的定义为 $f(x_i) &#x3D; -\log_2 p(x_i) $. 以下内容转载自 王木头学科学 (<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/467294700">https://zhuanlan.zhihu.com/p/467294700</a>)</p>
<h3 id="信息量"><a href="#信息量" class="headerlink" title="信息量"></a>信息量</h3><p>什么是信息? 一条信息的功能就是让你从“不知道”变得“知道”, 信息量肯定就是对信息的这个功能进行的度量了. 可是, 如果信息的使命就是让“不知道”变成“知道”, 也就是说这是一个“是否”的二值问题, 那信息也就没有度量的必要了, 反正就两种情况. 关键是, 一条信息不是“知道”和“不知道”非此即彼的, 它还能让你既不是完全不知道, 又不是完全知道. 如果是这样的话, 那对信息进行度量就有意义了, 就是去度量一下这个“知道”的程度. 这种既不是完全不知道, 又不是完全知道的状态还真有, 举个例子. </p>
<p>假如说有8只球队参加世界杯, 有这样两种情况：如果你什么消息都没有听说, 有人问你阿根廷夺冠没有啊, 你回答说不知道. 随后, 你看到一个消息, 说阿根廷已经进决赛了, 这个时候再问你阿根廷夺冠没有啊, 你还是说不知道. </p>
<img src="/2022/06/15/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/%E7%8E%8B1.jpg" class="" title="球队1">

<p>虽然两种情况, 你对阿根廷是否夺冠回答的都是不知道, 但是这里的“不知道”和“不知道”还是很不一样的. a情况的不知道, 因为还没有比赛所以阿根廷夺冠的概率是1&#x2F;8, b情况阿根廷已经进到决赛了, 虽然还没有最终夺冠, 但是夺冠的确定性已大大增加, 已经达到了1&#x2F;2. 所以说, “阿根廷进决赛”这个消息, 让你对阿根廷夺冠这个事件, 从完全不知道, 到有些知道了. 也就是说, 这个消息它应该是有信息量的. 从前面这个例子, 我们也能看出来对于阿根廷夺冠这件事, 不同的消息含有的信息量很可能是不同的. 如果我和你说, 我今天中午多吃了一个包子, 这虽然也是个消息, 但是这个消息对于阿根廷夺冠来说信息量就是0. 总结一下的话, 其实我们应该有这一个感觉了, 定性上来说, 信息量它应该是, 某个消息对“某个事件的确定程度改变了多少”进行的衡量. 而确定性改变了多少, 其实也就是前面说的那个概率的改变, 阿根廷夺冠从原来的1&#x2F;8变成了1&#x2F;2. 但是定量上来说, 信息量到底是多少呢? 难道就是凭着直觉, 简单地用1&#x2F;2减去1&#x2F;8, 用这个差值去定义信息量吗? 没有这么简单. </p>
<h3 id="信息量的公式推导"><a href="#信息量的公式推导" class="headerlink" title="信息量的公式推导"></a>信息量的公式推导</h3><p>信息量的良定义要想对信息量给出一个良定义, 不能产生自我矛盾, 就需要考虑一下不同情况中, 我们对信息量的理解是什么样的. 就比如, 我们可以看这样一种情况.   </p>
<img src="/2022/06/15/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/%E7%8E%8B2.jpg" class="" title="球队2">

<p>这里的3个箭头代表着3个消息, 绿色消息是阿根廷进入了决赛, 蓝色消息则是阿根廷直接夺得冠军, 这两个消息的起点都是一样的, 都是在你不知道任何比赛结果的时候听到的消息. 而橙色消息, 它则是依赖于绿色消息的, 它代表的是, 在你知道阿根廷进决赛之后, 又赢得决赛夺得冠军. 如果我们想要信息量来衡量3个消息, 那么我们可以看出信息量应该满足下面等式：</p>
<p>$$ 信息量(蓝色消息)&#x3D;信息量(绿色消息)+信息量(橙色消息) $$</p>
<p>一个消息的信息量具体是多少, 虽然我们现在还不知道, 但是我们可以确定, 这个信息量应该是和对应事件发生的概率有关. 于是我们就可以拿这个概率作为变量, 那计算信息量这个函数应该如下：</p>
<p>$$ 信息量(\frac{1}{8})&#x3D;信息量(\frac{1}{4})+信息量(\frac{1}{2})  ————————— ① $$</p>
<p>到这里其实还没有完, 因为函数里的变量是概率, 根据条件概率的性质, 我们知道这里还隐含着一个条件, 那就是：</p>
<p>$$ P(夺冠)&#x3D;P(夺冠|进决赛)×P(进决赛)  ————————— ② $$</p>
<p>把①和②一结合, 我们就可以发现这样一个关系：</p>
<p>$$ 信息量(\frac{1}{4} × \frac{1}{2})&#x3D;信息量(\frac{1}{4})+信息量(\frac{1}{2}) $$  </p>
<p>仔细看一下这个式子就能发现, 计算信息量的这个函数, 如果想要自洽, 想要是良定义的, 那么它必须满足一个条件, 那就是自变量的乘法等于函数值的加法. 满足这样这样的函数应该是什么样子的? 理论上来说, 满足这个性质的函数应该是有千千万万的, 但是其中最简单的应该就是对数运算log了. log对数运算是唯一满足这种关系的初等函数. 到现在, 我想大家心中都会有一个冲动, 就是把信息量定义为：  </p>
<img src="/2022/06/15/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/%E7%8E%8B3.png" class="" title="信息量1">

<p>不论是说奥卡姆剃刀原理, 还是说人们本能的喜欢偷懒, 这个用最简单的方式给出定义的冲动都特别正常. 我想, 当年香农给出信息量的定义的时候, 也是这么想的. 接下来需要确定的就是这个式子里的两个问号了, 系数是多少? 对数的底又是多少? 一切都为了简单, 不考虑别的话, 系数应该就是1了, 只不过需要确定的是, 到底是1还是-1. 如果硬规定, 系数就是1也行, 只不过我们现在做的并不是完全凭空发明出信息量这个概念, 如果是凭空创造出来的, 那么发明人怎么定那我们就怎么用. 我们现在面对的问题是, 信息量这个概念, 我们在日常生活中就在用, 只不过定理的定义不是很清晰, 我们现在做的其实是把这个定义换成更精确的数学方式表达出来, 所以数学的定义不应该和我们的口语表达有冲突. 所以到底是1还是-1, 就需要看一下我们口语中, 自变量（也就是那个概率值）越大函数值越大, 还是自变量越小函数值越大了. 还是看上面阿根廷夺冠的例子, 绿色消息是阿根廷进入决赛, 蓝色消息是阿根廷夺得冠军, 一个发生的概率是 $\frac{1}{4}$, 一个发生的概率是 $\frac{1}{8}$, 单从概率的数值上来看的话, 显然绿色消息值更大. 但是这两个消息那个信息量更大呢? 我们的感觉肯定是蓝色的消息信息量更大啊, 绿色的消息只是让阿根廷夺冠这件事概率增加了, 并没有完全确定, 而蓝色消息却是给出了一个完全确定的结果, 显然蓝色的消息带来的不确定程度的改变更剧烈, 也就是带来的信息量更大. 所以信息量, 它的自变量和函数值应该是一个反比关系, 也就是第一个问号, 那个系数应该是-1.   </p>
<img src="/2022/06/15/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/%E7%8E%8B4.png" class="" title="信息量2">

<p>剩下没有确定的就是对数运算的底了, 这里底到底取多少, 其实已经不那么重要了, 可以取e为底, 也可以取10为底, 还可以取2为底. 当然, 现在我们习惯的方式用2为底, 这样子计算出来的信息量单位是比特. 取不同的底, 其实就是信息量的单位不同, 以e为底的单位是纳特(nat)或者是nit, 以10为底的单位是哈特(Hart)或者是dit. 其中比特我们最熟悉, 这最早是由香农提出来的. 而以10为底的信息量, 最早是1928年有拉尔夫·哈特利(Ralph Hartley)提出来的, 后来图灵也用10为底计算过信息量, 只不过图灵把这样的信息量单位称为ban. 这里值得注意的是, 信息量是有单位的（也就是说信息量有量纲. 什么意思呢? 这里用bit作为例子来说明一下. 我们知道, 说到单位, 比如说米, 千克, 它们都是有一个基准尺度的, 具体长度是多少, 质量是多少, 都是与这个基准尺度做比较得出来的. 比如, 曾经米的基准就是子午线的千万分之一, 后来才改成用光速定义, 公斤的基准尺度曾经是用放在法国的国际千克原器的质量, 后来才改成用普朗克常数定义. 既然信息量也是有单位的, 那么这个bit单位的基准尺度是什么呢? 其实bit就是用像抛硬币这种“50%正, 50%反”的情况作为基准尺度的, 其他的bit数值都是与这个基准尺度比较得到的. $\frac{1}{2}$ 概率的事件是1bit, $\frac{1}{4}$ 概率的事件是2bit, 这就是说这两个概率分别可以用1个硬币和2个硬币等价表示. 至于 $\frac{1}{3}$ 的概率, 对应的信息量是约等于1.58bit. 虽然我们现实中不可能是抛1.58个硬币, 但是数学上还是可以这样来表示出来的. 这里在多说一下, 在计算机里面, 我们经常说8bit, 16bit这些词, 这些词不只表示一个信号里面含有的信息量, 还用来表示存储空间的大小. 这是为什么呢? 举个例子, 假如说计算机里面有一个16bit的空间, 这个空间里0, 1, 0, 1到底是怎么排列组合的, 是不确定的, 任何一种情况的概率都是 $\frac{1}{2^{16}}$. 当计算机接受到1个信息, 这里的空间存储上了一个2进制数字（具体是什么数字无所谓）, 这里的可能性就从原来的 $\frac{1}{2^{16}}$ 概率变成了确定的1, 这个信息量是多少? 就是16bit啊. 这个空间最多可以承载多少的信息量? 就是16bit了. 于是存储空间的大小和信息量统一了, 这也是bit又可以表示存储空间的原因. </p>
<h3 id="熵"><a href="#熵" class="headerlink" title="熵"></a>熵</h3><p>熵是一个系统里信息量的期望值对信息量了解之后, 我们就可以来看熵了. 熵这个概念, 现在已经比较出圈了, 本来一个学科里面很偏门的概念, 现在在互联网圈子里面却人尽皆知. 主要就是熵增这个概念太火了, 它涉及到了整个宇宙的宿命, 宇宙的未来就是在不可对抗的熵增过程中归于热寂. 那熵到底是什么呢? 在科普内容里面, 很少有人把熵的定义公式拿出来讲的, 都是说熵是对一个系统的混乱程度的度量. 当初的先贤们是如何提出熵这个概念的, 他们最初的想法是什么, 我们很难还原了, 不过我们现在还是可以对熵做逆向工程, 试着来理解一下, 前面说的系统的混乱程度到底是什么意思? 为什么用信息量可以去描述系统的混乱程度? 我们可以先来看这样一个问题, 有两场比赛, 假如说这两场比赛就是两个系统.   </p>
<img src="/2022/06/15/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/%E7%8E%8B5.jpg" class="" title="球队赢球1">

<p>一场比赛是比利时对战阿根廷（系统1）, 因为它们水平差不多, 所以两队赢球的概率都是50%. 另一场比赛是法国对中国（系统2）, 实力相差比较大, 所以法国赢球的概率99%, 中国赢球的概率是1%. 请问, 这两个系统那个的混乱程度更高? 这个问题并不是靠直觉马上就能回答出来的, 还是要琢磨一下. 法国对中国, 这个系统不出意外的话, 肯定是法国赢, 也就是最后的结果确定性更高. 而比利时对阿根廷, 这个就不能说意外不意外了, 谁赢都有可能, 所以最后结果是什么就很不确定. 这里我是用不确定的程度来描述两场比赛的, 其实这个不确定的程度也就是我们日常说的混乱程度, 比利时和阿根廷比赛, 因为结果特别不确定, 所以很混乱. 反过来说你, 一个屋子很混乱, 也就是你的袜子到底在哪里, 非常不确定. 既然和概率, 不确定性搭上关系了, 那么我们前面介绍的信息量就可以派上用场了. 两次比赛, 分别对应着两个可能的事件（系统1是“比利时赢”和“阿根廷赢”两个事件, 系统2是“法国赢”和“中国赢”两个事件）, 它们对应的信息量计算结果出来如下：</p>
<img src="/2022/06/15/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/%E7%8E%8B6.jpg" class="" title="球队赢球2">

<p>比利时对阵阿根廷, 不论谁获胜, 信息量都是1bit. 法国对阵中国, 法国赢球的概率很高, 所以他们赢球带来的信息量就很少, 但是如果中国赢球了, 那这个信息量就很大了, 超过了6.6bit. 这么看的话, 系统1这个系统里两个事件的信息量加起来才是2bit, 还没有中国赢球一个事件的信息量大, 如果用信息量来表示熵, 是不是就会有问题啊. 明明系统1更不确定, 但是计算出来却是系统1的信息量更少. 别急, 熵的确是“系统里面所有可能事件对应的信息量总和”, 只不过不是把它们简单地加起来就行了, 而是需要加权求和. 这个权重是什么? 就是这个事件发生的概率啊.   </p>
<img src="/2022/06/15/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/%E7%8E%8B7.jpg" class="" title="球队赢球3">

<p>加上权重之后, 就合理了, 从上图就可以看出系统1得到的值的确是比系统2更大了. 而且这个加上权重的动作也挺合理的, 就比如说, 中国队夺冠了这个事情如果发生了的话, 信息量的确还挺大的, 但是它得真发生了才行了, 可事实呢, 它只有1%的可能性发生, 99%的可能性都是法国夺冠. 所以, 一个系统到底含有多少信息量, 那还需要看具体一个事件对整个系统到底能贡献多少信息量才行. 如果事件没发生, 那就是没有贡献啊, 就不能放在总和里面. 越是一个事件贡献了多少信息量, 就可以理解成信息量乘上对应事件发生的概率. 那熵到底是什么? 这个问题就简单了, 熵就是所有事件对应的信息量的加权和, 那这个加权和是什么? 就是这个系统里面信息量的期望值啊. 那么我们就可以对熵做出如下定义了, 其中 $H(S)$ 表示S系统的熵, $E$ 是求期望, $I(x)$ 是求信息量, $P(x_i)$ 表示xi事件的概率.   </p>
<p>$$ H(S) &#x3D; -\sum_{i&#x3D;1}^m P(x_i) \cdot \log_2 P(x_i) $$</p>
<img src="/2022/06/15/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/%E7%8E%8B8.jpg" class="" title="系统S">

<p>现在我们已经知道熵到底是什么了. 我们最开始的目的是什么? 是比较两个概率分布, 一个表示真实的规律, 一个表示机器学习猜测的规律, 看看两个概率分布它们相差有多少. 现在有了熵, 我们是不是就可以直接比较两个概率分布的差距了呢? 把两个概率分布的熵都算出来, 然后看看相差多少. 哪有这么简单, 别忘了, 真实规律我们是不知道的, 既然不知道, 那它的熵还怎么求呢? 没有办法. 那么有没有什么方法, 即便不知道一个概率分布的熵具体是多少, 也能知道两个概率分布之间的差距是多少呢? 有！这就是KL散度和交叉熵了.</p>
<h3 id="KL散度（相对熵）和交叉熵"><a href="#KL散度（相对熵）和交叉熵" class="headerlink" title="KL散度（相对熵）和交叉熵"></a>KL散度（相对熵）和交叉熵</h3><p>假如说, 下面这个图表示的是两个系统的概率分布, 其中系统S代表的是真实的规律, 系统O代表的是机器学习模型里面猜测的那个规律.  </p>
<img src="/2022/06/15/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/%E7%8E%8B9.jpg" class="" title="系统O和S">

<p>这两个系统的概率分布如果是相同的话, 那么毫无疑问, 两个系统的熵也一定是相等的, 而且我还能大概确定, 两个系统越像, 熵应该是越接近的. 不过, 这个事情不能反过来想, 两个系统的熵相同, 两个系统的概率分布就一定相同吗? 好像并没有这么简单, 因为简单的一个数字, 维度太少了. 一张200元的高铁票和一件200元的衣服, 它们价格相同, 但是这两个东西却是天差地别. 所以, 看两个系统是不是相同, 不能是直接比较两个系统的熵, 这会太简单粗暴. 那怎么办呢? 这个时候就需要KL散度这个概念了. KL散度就不是粗暴的比较一个总体的熵了, 而是比较得更细致, 每一个事件xi对应的信息量, 都会拿来进行比较. 如果每一个事件的信息量都是相同的, 那么两个概率分布肯定就是相同的了. 于是KL散度就可以做出如下定义：  </p>
<img src="/2022/06/15/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/%E7%8E%8B10.jpg" class="" title="KL散度">

<p>可以注意到, 这个定义本质上也是一个加权求和, 求和的是两个系统中同一个事件的信息量的差值, 加的那个权重是其中一个系统里这个事件的概率值. 从这里也能看出来, 这里的系统S和系统O, 它们并不是平等的, 把S和O交换之后并不能保证得到相同的值. </p>
<img src="/2022/06/15/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/KL.png" class="" title="KL散度1">

<p>也就是说, KL散度它相当于会在两个系统中挑选了一个作为基准（我这里用的是S系统作为基准）, 拿另一个系统与这个基准进行比较. 因为这是用S系统的熵作为基准, 去衡量另一个系统O的熵, 所以KL散度也叫相对熵. 当KL散度给出来之后, 用熵直接比较太简单粗暴的问题给解决了, 但是这个东西我们应该怎么用呢? 直接看KL散度的定义的话, 还是很难想到怎么用的, 不过只需要对KL散度的定义变变形, 这个问题就会变得简单了.   </p>
<img src="/2022/06/15/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/%E7%8E%8B11.jpg" class="" title="吉布斯不等式">

<p>经过变形之后我们就能发现, KL散度可以被分成两个部分, 其中后面的那个部分计算出来就是系统S的熵, 这部分算出来是多少是与系统O无关的. 所以, 真正决定KL散度的其实是前面那部分, 它的大小决定着KL散度的大小. 于是这部分就可以被单独拿出来讨论, 所以它就被定义成为了交叉熵. 想知道系统S和系统O是否一样, 不需要去计算它们的KL散度, 只需要去看它们的交叉熵. 我们的目标是什么, 是希望机器学习模型中猜测出来的那个概率分布O, 与真实的概率分布S接近. 这个接近如果用KL散度来表示的话, 就是KL散度要尽可能地接近数值0, 正值太大, 负值太小都不行. 那如果我们的目标不用KL散度来表示, 而是用交叉熵来表示, 应该是什么样子的呢? 如果直接看前面推导出的那个式子, 我们可以看到, 我们的目标可以表示成交叉熵的值与系统S的熵最接近时, 目标达成. 但是这里也就有问题了, 这代表着如何能找到最合适的交叉熵, 要分两种情况来考虑：当交叉熵的值大于系统S的熵时, 我们的目标是寻找交叉熵最小的值当交叉熵的值小于系统S的熵时, 我们的目标是寻找交叉熵最大的值这个时候, 我们一般都会不禁地想, 如果只有一种情况该多好啊, 这样问题就简单了, 我们寻找最接近系统S的系统O, 就变成一个对交叉熵求最值的问题了, 如果是第一种情况就是求最小值, 如果是第二种情况就是求最大值. 我想数学家们也和我们有同样的想法, 所以他们真的从数学上证明了, 不需要两种情况都考虑, 只需要考虑第一种情况. 这是因为, 从数学上就可以证明, 交叉熵的值一定是会大于等于系统S的熵的. 所以, 只需要考虑如何对交叉熵求最小值就行了. 一个系统与系统S的交叉熵最小值, 那么这个系统与S最接近. 这个证明过程就不写了, 感兴趣的话, 大家可以自己去了解一下吉布斯不等式. （重点关注一下条件, 概率值pi和qi是归一的, 后面要用到）</p>
<img src="/2022/06/15/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/%E7%8E%8B12.jpg" class="" title="分类1">

<p>至此, 我们终于了解交叉熵到底是怎么来的, 以及为什么交叉熵最小的时候, 两个概率分布最接近. 但是, 这个概念是如何应用到神经网络里面的? 它对应的损失函数应该如何设计? 为什么求交叉熵最小的方法, 又可以被称为最大似然估计法? 7.“最小交叉熵”和“最大似然估计”两种损失函数等价要想把交叉熵这个概念应用到神经网络里面, 那我们首先需要做的是把神经网络变成一个概率问题. 这问题其实在上一个文章里面已经介绍过了（《损失函数是如何设计出来的》）, 假设说这是一个判断是猫是狗的二分问题, 那么真实规律和神经网络猜测的规律, 可以用下面两个概率分布来进行表示. 其中随机变量z, 表示这个规律对图片的判断结果.   </p>
<img src="/2022/06/15/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/%E7%8E%8B13.jpg" class="" title="分类2">

<p>于是, 交叉熵就可以写成如下形式, （因为是归一的, 所以可以用吉布斯不等式, 也就是KL散度可以转化成交叉熵问题）：</p>
<img src="/2022/06/15/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/%E7%8E%8B14.png" class="" title="分类3">

<p>不过, 只是这样的话, 我们是没有办法计算交叉熵的, 因为我们并不清楚P(zi,xi | 真实规律)和P(zi,xi | 猜测规律)的概率分布我们知道是什么? 是P(zi | xi ,真实规律)和P(zi | xi ,猜测规律)的概率, 这里不一样的是xi的位置, xi也就是输入的数据, 猫狗的图片从原来的随机变量, 变成了条件. 然后我们就可以得到下图的关系. 其中   表示神经网络在输入图片后的计算结果, 因为  经常是经过sigmoid计算后的结果, 所以可以直接看做是一个概率值. </p>
<img src="/2022/06/15/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/%E7%8E%8B15.jpg" class="" title="分类4">

<p>从P(zi,xi | 真实规律), 到P(zi | xi ,真实规律), 我们知道中间差了一个P(xi)        P(zi,xi | 真实规律)&#x3D;P(zi | xi ,真实规律) × P(xi)于是交叉熵就可以写成下面的样子：</p>


<p>这里的P(xi)其实代表的就是, 这个训练用的图片是按照什么概率从茫茫多的图片中抽样出来的. 这个值我们并不清楚, 不过训练集的图片我们基本上也就是认为它们是被随机挑选出来的, 也就是说不同图片的概率应该都是相同的. 于是P(xi)就可以看做是一个常数. 又因为我们希望求的是在交叉熵取最小值时的“猜测规律”的情况, 所以当P(xi)是常数的时候, 对最后的结果是不会有影响的. 也就是说：</p>
<img src="/2022/06/15/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/%E7%8E%8B17.jpg" class="" title="分类6">

<img src="/2022/06/15/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/%E7%8E%8B18.jpg" class="" title="分类7">


<p>当然, 我们更习惯的用法, 其实是将猫狗用1和0来表示, 如果说用1表示是猫, 0表示是狗, 那么y作为图片的标签值有：猫的标签值y&#x3D;1, 狗的标签值y&#x3D;0. 于是前面的那个概率关系就可以变成如下的样子：</p>
<img src="/2022/06/15/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/%E7%8E%8B19.jpg" class="" title="分类8">

<p>然后我们再对上面几种情况归纳整理一下, 就可以得出最小交叉熵的最终表达形式了, 其中i∈{1,2,…,n}, 表示的是训练集图片有n个, j∈{1,2}, 表示这是一个二分类问题：</p>
<img src="/2022/06/15/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/%E7%8E%8B20.jpg" class="" title="分类9">

<img src="/2022/06/15/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/%E7%8E%8B21.jpg" class="" title="分类10">


<p>到了这一步, 是不是就非常眼熟了? 我们可以再把最开始吴恩达老师课程里的那个损失函数表达式拿下来看一下：</p>
<img src="/2022/06/15/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/%E7%8E%8B22.jpg" class="" title="损失函数">

<p>是不是一模一样的? 吴恩达老师给出的是一个图片的计算公式, 如果考虑的是把所有图片的交叉熵都计算出来, 就是我写出来的样子了. 如果你再去看一下之前《损失函数是如何设计出来的》在最后整理出来的, 用最大似然估计得到的损失函数, 也是一模一样的. 也就是说, 最小交叉熵和最大似然估计, 它们殊途同归, 本质上是等价的. 当然, 这里还有多提一下, 从数学上来看, 最小交叉熵和最大似然估计是等价的, 但是硬要较真儿的话, 两个方法在物理上还是不同的. 因为, 交叉熵是有量纲的, 而似然值没有量纲, 最大似然值最后之所以会出现log和负号, 也只是为了计算的方法, 本身并没有物理意义. 交叉熵就不同了, 它的log和负号, 是让它有单位的关键. </p>

        </div>

        
            <section class="post-copyright">
                
                    <p class="copyright-item">
                        <span>Author:</span>
                        <span>Reggie</span>
                    </p>
                
                
                    <p class="copyright-item">
                        <span>Permalink:</span>
                        <span><a href="https://reginald-l.github.io/2022/06/15/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/">https://reginald-l.github.io/2022/06/15/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/</a></span>
                    </p>
                
                
                    <p class="copyright-item">
                        <span>License:</span>
                        <span>Copyright (c) 2022 <a target="_blank" rel="noopener" href="http://creativecommons.org/licenses/by-nc/4.0/">CC-BY-NC-4.0</a> LICENSE</span>
                    </p>
                
                
                     <p class="copyright-item">
                         <span>Slogan:</span>
                         <span><strong>I am a slow walker, but I never walk backwards!!!</strong></span>
                     </p>
                

            </section>
        
        <section class="post-tags">
            <div>
                <span>Tag(s):</span>
                <span class="tag">
                    
                    
                        <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"># 深度学习</a>
                    
                        <a href="/tags/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/"># 损失函数</a>
                    
                        
                </span>
            </div>
            <div>
                <a href="javascript:window.history.back();">back</a>
                <span>· </span>
                <a href="/">home</a>
            </div>
        </section>
        <section class="post-nav">
            
                <a class="prev" rel="prev" href="/2022/06/17/%E7%8B%AC%E7%AB%8B%E5%90%8C%E5%88%86%E5%B8%83/">独立同分布</a>
            
            
            <a class="next" rel="next" href="/2022/05/05/softmax/">softmax</a>
            
        </section>


    </article>
</div>

            </div>
            <footer id="footer" class="footer">
    <div class="copyright">
        <span> Copyright © Reggie | 2022 </span>
    </div>
</footer>

    </div>
</body>

</html>